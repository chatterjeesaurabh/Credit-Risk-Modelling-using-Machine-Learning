{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Risk Modelling\n",
    "\n",
    "### Saurabh Chatterjee\n",
    "### Part - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "import warnings\n",
    "import os   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <th>Tot_TL_closed_L12M</th>\n",
       "      <th>pct_tl_closed_L12M</th>\n",
       "      <th>Tot_Missed_Pmnt</th>\n",
       "      <th>CC_TL</th>\n",
       "      <th>Home_TL</th>\n",
       "      <th>PL_TL</th>\n",
       "      <th>Secured_TL</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_PL_enq_L6m_of_ever</th>\n",
       "      <th>pct_CC_enq_L6m_of_ever</th>\n",
       "      <th>HL_Flag</th>\n",
       "      <th>GL_Flag</th>\n",
       "      <th>MARITALSTATUS</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>last_prod_enq2</th>\n",
       "      <th>first_prod_enq2</th>\n",
       "      <th>Approved_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>12TH</td>\n",
       "      <td>M</td>\n",
       "      <td>PL</td>\n",
       "      <td>PL</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Single</td>\n",
       "      <td>GRADUATE</td>\n",
       "      <td>F</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>SSC</td>\n",
       "      <td>M</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>others</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>POST-GRADUATE</td>\n",
       "      <td>M</td>\n",
       "      <td>AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Married</td>\n",
       "      <td>12TH</td>\n",
       "      <td>M</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>PL</td>\n",
       "      <td>P3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  pct_tl_open_L6M  pct_tl_closed_L6M  Tot_TL_closed_L12M  \\\n",
       "0           0            0.000                0.0                   0   \n",
       "1           1            0.000                0.0                   0   \n",
       "2           2            0.125                0.0                   0   \n",
       "3           3            0.000                0.0                   0   \n",
       "4           4            0.000                0.0                   1   \n",
       "\n",
       "   pct_tl_closed_L12M  Tot_Missed_Pmnt  CC_TL  Home_TL  PL_TL  Secured_TL  \\\n",
       "0               0.000                0      0        0      4           1   \n",
       "1               0.000                0      0        0      0           0   \n",
       "2               0.000                1      0        0      0           2   \n",
       "3               0.000                0      0        0      0           3   \n",
       "4               0.167                0      0        0      0           6   \n",
       "\n",
       "   ...  pct_PL_enq_L6m_of_ever  pct_CC_enq_L6m_of_ever  HL_Flag  GL_Flag  \\\n",
       "0  ...                   0.000                     0.0        1        0   \n",
       "1  ...                   0.000                     0.0        0        0   \n",
       "2  ...                   0.000                     0.0        1        0   \n",
       "3  ...                   0.000                     0.0        0        0   \n",
       "4  ...                   0.429                     0.0        1        0   \n",
       "\n",
       "   MARITALSTATUS      EDUCATION  GENDER  last_prod_enq2  first_prod_enq2  \\\n",
       "0        Married           12TH       M              PL               PL   \n",
       "1         Single       GRADUATE       F    ConsumerLoan     ConsumerLoan   \n",
       "2        Married            SSC       M    ConsumerLoan           others   \n",
       "3        Married  POST-GRADUATE       M              AL               AL   \n",
       "4        Married           12TH       M    ConsumerLoan               PL   \n",
       "\n",
       "   Approved_Flag  \n",
       "0             P2  \n",
       "1             P2  \n",
       "2             P2  \n",
       "3             P1  \n",
       "4             P3  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel(\"final_filtered_dataset.xlsx\")       # loading our filtered dataset (prepared in Part-1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MARITALSTATUS',\n",
       " 'EDUCATION',\n",
       " 'GENDER',\n",
       " 'last_prod_enq2',\n",
       " 'first_prod_enq2',\n",
       " 'Approved_Flag']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical Columns:\n",
    "cat_clumns = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        cat_clumns.append(i)\n",
    "\n",
    "cat_clumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Married' 'Single']\n",
      "['12TH' 'GRADUATE' 'SSC' 'POST-GRADUATE' 'UNDER GRADUATE' 'OTHERS'\n",
      " 'PROFESSIONAL']\n",
      "['M' 'F']\n",
      "['PL' 'ConsumerLoan' 'AL' 'CC' 'others' 'HL']\n",
      "['PL' 'ConsumerLoan' 'others' 'AL' 'HL' 'CC']\n"
     ]
    }
   ],
   "source": [
    "# Encoding Categorical features into Numerical:\n",
    "\n",
    "print(df['MARITALSTATUS'].unique())             # One-Hot Encoding\n",
    "print(df['EDUCATION'].unique())                 # Label / Ordinal Encoding  (since its categories have a rank/order)\n",
    "print(df['GENDER'].unique())                    # One-Hot Encoding\n",
    "print(df['last_prod_enq2'].unique())            # One-Hot Encoding\n",
    "print(df['first_prod_enq2'].unique())           # One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION\n",
      "3    18931\n",
      "2    11703\n",
      "1     9532\n",
      "4     1898\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 44 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Unnamed: 0                 42064 non-null  int64  \n",
      " 1   pct_tl_open_L6M            42064 non-null  float64\n",
      " 2   pct_tl_closed_L6M          42064 non-null  float64\n",
      " 3   Tot_TL_closed_L12M         42064 non-null  int64  \n",
      " 4   pct_tl_closed_L12M         42064 non-null  float64\n",
      " 5   Tot_Missed_Pmnt            42064 non-null  int64  \n",
      " 6   CC_TL                      42064 non-null  int64  \n",
      " 7   Home_TL                    42064 non-null  int64  \n",
      " 8   PL_TL                      42064 non-null  int64  \n",
      " 9   Secured_TL                 42064 non-null  int64  \n",
      " 10  Unsecured_TL               42064 non-null  int64  \n",
      " 11  Other_TL                   42064 non-null  int64  \n",
      " 12  Age_Oldest_TL              42064 non-null  int64  \n",
      " 13  Age_Newest_TL              42064 non-null  int64  \n",
      " 14  time_since_recent_payment  42064 non-null  int64  \n",
      " 15  max_recent_level_of_deliq  42064 non-null  int64  \n",
      " 16  num_deliq_6_12mts          42064 non-null  int64  \n",
      " 17  num_times_60p_dpd          42064 non-null  int64  \n",
      " 18  num_std_12mts              42064 non-null  int64  \n",
      " 19  num_sub                    42064 non-null  int64  \n",
      " 20  num_sub_6mts               42064 non-null  int64  \n",
      " 21  num_sub_12mts              42064 non-null  int64  \n",
      " 22  num_dbt                    42064 non-null  int64  \n",
      " 23  num_dbt_12mts              42064 non-null  int64  \n",
      " 24  num_lss                    42064 non-null  int64  \n",
      " 25  recent_level_of_deliq      42064 non-null  int64  \n",
      " 26  CC_enq_L12m                42064 non-null  int64  \n",
      " 27  PL_enq_L12m                42064 non-null  int64  \n",
      " 28  time_since_recent_enq      42064 non-null  int64  \n",
      " 29  enq_L3m                    42064 non-null  int64  \n",
      " 30  NETMONTHLYINCOME           42064 non-null  int64  \n",
      " 31  Time_With_Curr_Empr        42064 non-null  int64  \n",
      " 32  CC_Flag                    42064 non-null  int64  \n",
      " 33  PL_Flag                    42064 non-null  int64  \n",
      " 34  pct_PL_enq_L6m_of_ever     42064 non-null  float64\n",
      " 35  pct_CC_enq_L6m_of_ever     42064 non-null  float64\n",
      " 36  HL_Flag                    42064 non-null  int64  \n",
      " 37  GL_Flag                    42064 non-null  int64  \n",
      " 38  MARITALSTATUS              42064 non-null  object \n",
      " 39  EDUCATION                  42064 non-null  int32  \n",
      " 40  GENDER                     42064 non-null  object \n",
      " 41  last_prod_enq2             42064 non-null  object \n",
      " 42  first_prod_enq2            42064 non-null  object \n",
      " 43  Approved_Flag              42064 non-null  object \n",
      "dtypes: float64(5), int32(1), int64(33), object(5)\n",
      "memory usage: 14.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Label / Ordinal Encoding: [EDUCATION] Column\n",
    "\n",
    "df.loc[df['EDUCATION'] == 'SSC', ['EDUCATION']]              = 1\n",
    "df.loc[df['EDUCATION'] == '12TH', ['EDUCATION']]             = 2\n",
    "df.loc[df['EDUCATION'] == 'GRADUATE', ['EDUCATION']]         = 3\n",
    "df.loc[df['EDUCATION'] == 'UNDER GRADUATE', ['EDUCATION']]   = 3\n",
    "df.loc[df['EDUCATION'] == 'POST-GRADUATE', ['EDUCATION']]    = 4\n",
    "df.loc[df['EDUCATION'] == 'OTHERS', ['EDUCATION']]           = 1         # 'OTHERS': (assigned = SSC = 1 ) : has to be verified by the business end user\n",
    "df.loc[df['EDUCATION'] == 'PROFESSIONAL', ['EDUCATION']]     = 3\n",
    "\n",
    "print(df['EDUCATION'].value_counts())               # count of each Education category\n",
    "df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 56 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Unnamed: 0                    42064 non-null  int64  \n",
      " 1   pct_tl_open_L6M               42064 non-null  float64\n",
      " 2   pct_tl_closed_L6M             42064 non-null  float64\n",
      " 3   Tot_TL_closed_L12M            42064 non-null  int64  \n",
      " 4   pct_tl_closed_L12M            42064 non-null  float64\n",
      " 5   Tot_Missed_Pmnt               42064 non-null  int64  \n",
      " 6   CC_TL                         42064 non-null  int64  \n",
      " 7   Home_TL                       42064 non-null  int64  \n",
      " 8   PL_TL                         42064 non-null  int64  \n",
      " 9   Secured_TL                    42064 non-null  int64  \n",
      " 10  Unsecured_TL                  42064 non-null  int64  \n",
      " 11  Other_TL                      42064 non-null  int64  \n",
      " 12  Age_Oldest_TL                 42064 non-null  int64  \n",
      " 13  Age_Newest_TL                 42064 non-null  int64  \n",
      " 14  time_since_recent_payment     42064 non-null  int64  \n",
      " 15  max_recent_level_of_deliq     42064 non-null  int64  \n",
      " 16  num_deliq_6_12mts             42064 non-null  int64  \n",
      " 17  num_times_60p_dpd             42064 non-null  int64  \n",
      " 18  num_std_12mts                 42064 non-null  int64  \n",
      " 19  num_sub                       42064 non-null  int64  \n",
      " 20  num_sub_6mts                  42064 non-null  int64  \n",
      " 21  num_sub_12mts                 42064 non-null  int64  \n",
      " 22  num_dbt                       42064 non-null  int64  \n",
      " 23  num_dbt_12mts                 42064 non-null  int64  \n",
      " 24  num_lss                       42064 non-null  int64  \n",
      " 25  recent_level_of_deliq         42064 non-null  int64  \n",
      " 26  CC_enq_L12m                   42064 non-null  int64  \n",
      " 27  PL_enq_L12m                   42064 non-null  int64  \n",
      " 28  time_since_recent_enq         42064 non-null  int64  \n",
      " 29  enq_L3m                       42064 non-null  int64  \n",
      " 30  NETMONTHLYINCOME              42064 non-null  int64  \n",
      " 31  Time_With_Curr_Empr           42064 non-null  int64  \n",
      " 32  CC_Flag                       42064 non-null  int64  \n",
      " 33  PL_Flag                       42064 non-null  int64  \n",
      " 34  pct_PL_enq_L6m_of_ever        42064 non-null  float64\n",
      " 35  pct_CC_enq_L6m_of_ever        42064 non-null  float64\n",
      " 36  HL_Flag                       42064 non-null  int64  \n",
      " 37  GL_Flag                       42064 non-null  int64  \n",
      " 38  EDUCATION                     42064 non-null  int32  \n",
      " 39  Approved_Flag                 42064 non-null  object \n",
      " 40  MARITALSTATUS_Married         42064 non-null  bool   \n",
      " 41  MARITALSTATUS_Single          42064 non-null  bool   \n",
      " 42  GENDER_F                      42064 non-null  bool   \n",
      " 43  GENDER_M                      42064 non-null  bool   \n",
      " 44  last_prod_enq2_AL             42064 non-null  bool   \n",
      " 45  last_prod_enq2_CC             42064 non-null  bool   \n",
      " 46  last_prod_enq2_ConsumerLoan   42064 non-null  bool   \n",
      " 47  last_prod_enq2_HL             42064 non-null  bool   \n",
      " 48  last_prod_enq2_PL             42064 non-null  bool   \n",
      " 49  last_prod_enq2_others         42064 non-null  bool   \n",
      " 50  first_prod_enq2_AL            42064 non-null  bool   \n",
      " 51  first_prod_enq2_CC            42064 non-null  bool   \n",
      " 52  first_prod_enq2_ConsumerLoan  42064 non-null  bool   \n",
      " 53  first_prod_enq2_HL            42064 non-null  bool   \n",
      " 54  first_prod_enq2_PL            42064 non-null  bool   \n",
      " 55  first_prod_enq2_others        42064 non-null  bool   \n",
      "dtypes: bool(16), float64(5), int32(1), int64(33), object(1)\n",
      "memory usage: 13.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <th>Tot_TL_closed_L12M</th>\n",
       "      <th>pct_tl_closed_L12M</th>\n",
       "      <th>Tot_Missed_Pmnt</th>\n",
       "      <th>CC_TL</th>\n",
       "      <th>Home_TL</th>\n",
       "      <th>PL_TL</th>\n",
       "      <th>Secured_TL</th>\n",
       "      <th>...</th>\n",
       "      <th>last_prod_enq2_ConsumerLoan</th>\n",
       "      <th>last_prod_enq2_HL</th>\n",
       "      <th>last_prod_enq2_PL</th>\n",
       "      <th>last_prod_enq2_others</th>\n",
       "      <th>first_prod_enq2_AL</th>\n",
       "      <th>first_prod_enq2_CC</th>\n",
       "      <th>first_prod_enq2_ConsumerLoan</th>\n",
       "      <th>first_prod_enq2_HL</th>\n",
       "      <th>first_prod_enq2_PL</th>\n",
       "      <th>first_prod_enq2_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  pct_tl_open_L6M  pct_tl_closed_L6M  Tot_TL_closed_L12M  \\\n",
       "0           0            0.000                0.0                   0   \n",
       "1           1            0.000                0.0                   0   \n",
       "2           2            0.125                0.0                   0   \n",
       "3           3            0.000                0.0                   0   \n",
       "4           4            0.000                0.0                   1   \n",
       "\n",
       "   pct_tl_closed_L12M  Tot_Missed_Pmnt  CC_TL  Home_TL  PL_TL  Secured_TL  \\\n",
       "0               0.000                0      0        0      4           1   \n",
       "1               0.000                0      0        0      0           0   \n",
       "2               0.000                1      0        0      0           2   \n",
       "3               0.000                0      0        0      0           3   \n",
       "4               0.167                0      0        0      0           6   \n",
       "\n",
       "   ...  last_prod_enq2_ConsumerLoan  last_prod_enq2_HL  last_prod_enq2_PL  \\\n",
       "0  ...                        False              False               True   \n",
       "1  ...                         True              False              False   \n",
       "2  ...                         True              False              False   \n",
       "3  ...                        False              False              False   \n",
       "4  ...                         True              False              False   \n",
       "\n",
       "   last_prod_enq2_others  first_prod_enq2_AL  first_prod_enq2_CC  \\\n",
       "0                  False               False               False   \n",
       "1                  False               False               False   \n",
       "2                  False               False               False   \n",
       "3                  False                True               False   \n",
       "4                  False               False               False   \n",
       "\n",
       "   first_prod_enq2_ConsumerLoan  first_prod_enq2_HL  first_prod_enq2_PL  \\\n",
       "0                         False               False                True   \n",
       "1                          True               False               False   \n",
       "2                         False               False               False   \n",
       "3                         False               False               False   \n",
       "4                         False               False                True   \n",
       "\n",
       "   first_prod_enq2_others  \n",
       "0                   False  \n",
       "1                   False  \n",
       "2                    True  \n",
       "3                   False  \n",
       "4                   False  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-Hot Encoding:\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS','GENDER', 'last_prod_enq2' ,'first_prod_enq2'])        ## FINAL Prepared Data\n",
    "\n",
    "df_encoded.info()\n",
    "k = df_encoded.describe()\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_encoded['Approved_Flag']\n",
    "X = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7648876738381077\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.8439716312056738\n",
      "Recall: 0.7041420118343196\n",
      "F1 Score: 0.767741935483871\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.7940283400809717\n",
      "Recall: 0.9330029732408325\n",
      "F1 Score: 0.8579239952610953\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4444444444444444\n",
      "Recall: 0.20528301886792452\n",
      "F1 Score: 0.2808466701084151\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7224926971762414\n",
      "Recall: 0.7210884353741497\n",
      "F1 Score: 0.7217898832684825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):        # Class-wise Precision, Recall and F1\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.8243386243386244\n",
      "Recall: 0.7682445759368837\n",
      "F1 Score: 0.7953037263910159\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8228051391862955\n",
      "Recall: 0.9139742319127849\n",
      "F1 Score: 0.8659968072119447\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4692874692874693\n",
      "Recall: 0.28830188679245283\n",
      "F1 Score: 0.35717625058438524\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7219047619047619\n",
      "Recall: 0.7366375121477162\n",
      "F1 Score: 0.7291967291967293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)      # Label Encoding Target variable: has four level classes: P1, P2, P3, P4\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):            # Class-wise Precision, Recall and F1\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n",
    "\n",
    "# Accuracy: 0.78\n",
    "\n",
    "# P3 Accuracy and F1 is Worse: \n",
    "# Reason: the data for P3 is ambigUous: its Credit Score range is very large:\n",
    "# Credit Score rangeS:      P1: 701-811,    P2: 669-700,    P3: 489-776     , P4: 469-658\n",
    "# P3 range is very low to very high entering into P2 and P4 ranges. -> so the model is also getting confused : and giving bad accuracy for P3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: \n",
    "- Random Forest = 0.76\n",
    "- XGBoost = 0.78 : Better (F1 Score is also Better)\n",
    "\n",
    "P3 Accuracy and F1 is Worse: \n",
    "- Reason: the data for P3 is ambiguous: its Credit Score range is very large:\n",
    "- **Credit Score** ranges:      P1: 701-811,    P2: 669-700,    **P3: 489-776**     , P4: 469-658\n",
    "- P3 range is very low to very high entering into P2 and P4 ranges. -> so the model is also getting confused : and giving bad accuracy for P3.\n",
    "\n",
    "Let's do further Feature Engineering and Fine-Tuning to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Metrics:\n",
    "1. Classification:\n",
    "- Accuracy\n",
    "- Precision and Recall : for Imbalanced dataset : but there is trade-off between them, so difficulty to follow both separately, solution: F1 Score\n",
    "- F1 Score : single metric to measure both Precision and Recall together.\n",
    "\n",
    "2. Regression:\n",
    "- MAE: \n",
    "- MSE:  Values are squared so less interpretability.\n",
    "- RMSE: Better measure than MSE as its values are comparable to the target value and so can be better interpretated than MSE. \\\n",
    "**Drawback**: *RMSE is scale dependent*: alone RMSE cannot give any idea of how much error it is (low or high), without knowing the scale of the target numerical values.\n",
    "- MAPE: Mean Absolute Percentage Error = Avg (Absolute Error / Actual Value) % : *Scale Dependent*. \\\n",
    "**Drawback**: Even if one of the Actual value is 0, the MAPE cannot be calculated.\n",
    "- R2: *Scale Independent* : gives absolute score between 0-1 : BEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "- For which combination of hyperparameters we are getting best Accuracy / F1 Score.\n",
    "- First check **Train Accuracy / Score** : if it is High then only measure the **Test Accuracy / Score** : Check *Underfitting / Bias*.\n",
    "- Then determine **Test Accuracy / Score** : if it is also High then Good. If it is less : *Overfitting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Class p1:\n",
      "Precision: 0.8255813953488372\n",
      "Recall: 0.7702169625246549\n",
      "F1 Score: 0.7969387755102041\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8240143369175628\n",
      "Recall: 0.9113974231912785\n",
      "F1 Score: 0.8655058823529411\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4500601684717208\n",
      "Recall: 0.28226415094339624\n",
      "F1 Score: 0.34693877551020413\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7149621212121212\n",
      "Recall: 0.7337220602526725\n",
      "F1 Score: 0.7242206235011991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standardizing Some Numerical Columns:\n",
    "# Apply Standard Scaler:\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "X = df_encoded.drop(['Approved_Flag'], axis=1)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_be_scaled = ['Age_Oldest_TL','Age_Newest_TL','time_since_recent_payment',\n",
    "'max_recent_level_of_deliq','recent_level_of_deliq',\n",
    "'time_since_recent_enq','NETMONTHLYINCOME','Time_With_Curr_Empr']\n",
    "\n",
    "# Performing SCALING on Train & Test Data SEPARATELY : *to prevent Data Leakage* :\n",
    "for i in columns_to_be_scaled: \n",
    "    column_data_train = X_train[i].values.reshape(-1, 1)\n",
    "    column_data_test = X_test[i].values.reshape(-1, 1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    scaled_column_train = scaler.fit_transform(column_data_train)\n",
    "    scaled_column_test = scaler.fit_transform(column_data_test)\n",
    "\n",
    "    X_train[i] = scaled_column_train\n",
    "    X_test[i] = scaled_column_test\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "# No improvement in metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200, 'alpha': 1, 'colsample_bytree': 0.9}\n",
      "Test Accuracy: 0.81879472245\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning in XGBoost:\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the XGBClassifier with the initial set of hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],         # number of trees in the model. Increasing this value generally improves model performance, but can also lead to overfitting.\n",
    "    'max_depth': [3, 5, 7],                 # maximum depth of the trees in the model\n",
    "    'learning_rate': [0.01, 0.1, 0.2],      # Step size shrinkage used in update to prevent overfitting. After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative.\n",
    "    'alpha' : [1, 10, 100],                 # L1 regularization term on weights\n",
    "    'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 0.9],      # subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed.\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200, 'alpha': 1, 'colsample_bytree': 0.9} | Accuracy: 0.81\n",
    "# Accuracy Improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis: Explain to Business End User\n",
    "\n",
    "P1: Best \\\n",
    "P2: Second Best \\\n",
    "P3: Third Best \\\n",
    "P4: Last \\\n",
    "\n",
    "**Risk Appetite:** How much the Bank is willing to sell loan.\n",
    "- Low : not willing to sell too much : <U>Target already achieved</U> : focus only on P1\n",
    "- High : willing to sell more loans : <U>Target far from being achieved</U> : accept P1, P2, P3 also. \n",
    "\n",
    "**Business Interpretation**: P1, P2 covers the risks. P3, P4 can be used to achieve target.\n",
    "\n",
    "**Feedback Loop / Model Retraining**:\n",
    "- Update data features, labels and model based on the feedback received from the end business user.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Hyperparameter Tuning Code:\n",
    "\n",
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#   'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 0.9],      # subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed.\n",
    "#   'learning_rate'   : [0.001, 0.01, 0.1, 1],          # Step size shrinkage used in update to prevent overfitting. After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative.\n",
    "#   'max_depth'       : [3, 5, 8, 10],\n",
    "#   'alpha'           : [1, 10, 100],                   # L1 regularization term on weights\n",
    "#   'n_estimators'    : [10,50,100]                     # number of trees in the model. Increasing this value generally improves model performance, but can also lead to overfitting.\n",
    "# }\n",
    "\n",
    "# index = 0\n",
    "\n",
    "# answers_grid = {\n",
    "#     'combination'       :[],\n",
    "#     'train_Accuracy'    :[],\n",
    "#     'test_Accuracy'     :[],\n",
    "#     'colsample_bytree'  :[],\n",
    "#     'learning_rate'     :[],\n",
    "#     'max_depth'         :[],\n",
    "#     'alpha'             :[],\n",
    "#     'n_estimators'      :[]\n",
    "\n",
    "#     }\n",
    "\n",
    "\n",
    "# # Loop through each combination of hyperparameters\n",
    "# for colsample_bytree in param_grid['colsample_bytree']:\n",
    "#   for learning_rate in param_grid['learning_rate']:\n",
    "#     for max_depth in param_grid['max_depth']:\n",
    "#       for alpha in param_grid['alpha']:\n",
    "#           for n_estimators in param_grid['n_estimators']:\n",
    "             \n",
    "#               index = index + 1\n",
    "             \n",
    "#               # Define and train the XGBoost model\n",
    "#               model = xgb.XGBClassifier(objective='multi:softmax',  \n",
    "#                                        num_class=4,\n",
    "#                                        colsample_bytree = colsample_bytree,\n",
    "#                                        learning_rate = learning_rate,\n",
    "#                                        max_depth = max_depth,\n",
    "#                                        alpha = alpha,\n",
    "#                                        n_estimators = n_estimators)\n",
    "               \n",
    "       \n",
    "                     \n",
    "#               y = df_encoded['Approved_Flag']\n",
    "#               x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "#               label_encoder = LabelEncoder()\n",
    "#               y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "#               x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#               model.fit(x_train, y_train)\n",
    "  \n",
    "\n",
    "       \n",
    "#               # Predict on training and testing sets\n",
    "#               y_pred_train = model.predict(x_train)\n",
    "#               y_pred_test = model.predict(x_test)\n",
    "       \n",
    "       \n",
    "#               # Calculate train and test results\n",
    "              \n",
    "#               train_accuracy =  accuracy_score (y_train, y_pred_train)\n",
    "#               test_accuracy  =  accuracy_score (y_test , y_pred_test)\n",
    "              \n",
    "              \n",
    "       \n",
    "#               # Include into the lists\n",
    "#               answers_grid ['combination']   .append(index)\n",
    "#               answers_grid ['train_Accuracy']    .append(train_accuracy)\n",
    "#               answers_grid ['test_Accuracy']     .append(test_accuracy)\n",
    "#               answers_grid ['colsample_bytree']   .append(colsample_bytree)\n",
    "#               answers_grid ['learning_rate']      .append(learning_rate)\n",
    "#               answers_grid ['max_depth']          .append(max_depth)\n",
    "#               answers_grid ['alpha']              .append(alpha)\n",
    "#               answers_grid ['n_estimators']       .append(n_estimators)\n",
    "       \n",
    "       \n",
    "#               # Print results for this combination\n",
    "#               print(f\"Combination {index}\")\n",
    "#               print(f\"colsample_bytree: {colsample_bytree}, learning_rate: {learning_rate}, max_depth: {max_depth}, alpha: {alpha}, n_estimators: {n_estimators}\")\n",
    "#               print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
    "#               print(f\"Test Accuracy : {test_accuracy :.2f}\")\n",
    "#               print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
